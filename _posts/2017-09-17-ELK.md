---
layout: post
title:  "ELK日志实时分析系统搭建"
date:   2017-09-17 23:00:05
categories: ELK
tags:  ElasticSearch Filebeat kibana
excerpt: ELK日志实时分析系统搭建。
---

## 1. 概述

采用ElasticSearch作为日志存储和搜索的引擎，Filebeat代替Logstash作为日志采集器，Kibana作为前台搜索和展示界面。

## 2. 总体规划

用途 | 服务器名 | IP地址 | 类型 | 配置 | 操作系统
---|---|---|--- | ---|---
ElasticSearch节点1 | Test-ElasticSearch-1  | 20.17.0.51 | Master=true;Data=true | 4c 8GB | CentOS7
ElasticSearch节点2 | Test-ElasticSearch-2  | 20.17.0.52 | Master=true;Data=true | 4c 8GB  | CentOS7
ElasticSearch节点3 | Test-ElasticSearch-3  | 20.17.0.53 | Master=true;Data=true | 4c 8GB  | CentOS7
ElasticSearch节点4 | Test-ElasticSearch-4  | 20.17.0.54 | Master=true;Data=true | 4c 8GB  | CentOS7
ElasticSearch节点5 | Test-ElasticSearch-5  | 20.17.0.55 | Master=true;Data=true | 4c 8GB | CentOS7
Kibana节点1 | Test-Kibana-1 | 20.17.0.61 | |  4c 4GB  | CentOS7
Kibana节点2 | Test-Kibana-2 | 20.17.0.62 | |  4c 4GB  | CentOS7
ningx（已有） | nginx-1 | 20.17.0.180 | |  2c 4GB | CentOS7

## 3. 准备工作

### 3.1. 软件准备

分别使用软件当前的最新稳定版本：
- ElasticSearch 5.6.0

```
https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.0.tar.gz
```

-  Kibana 5.6.0
```
https://artifacts.elastic.co/downloads/kibana/kibana-5.6.0-linux-x86_64.tar.gz
```
- Filebeat 5.6.0
```
https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.0-linux-x86_64.tar.gz
```

- X-Pack 5.6.0
```
https://artifacts.elastic.co/downloads/packs/x-pack/x-pack-5.6.0.zip
```

- Java SE Development Kit 8u144

```
http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
```

- 注册一个Free Basic License，使用X-Pack功能需要每年免费续License

```
https://register.elastic.co/
```

所有的下载文件，上传至 ```/usr/users/sw/download/``` 路径下。

### 3.2. 系统参数设置

#### 3.2.1. vm.max_map_count
```
vi /etc/sysctl.conf 
```
添加

```
vm.max_map_count=655360
```
然后执行
```
sysctl -p
```
立即生效。

#### 3.2.2. OpenFiles数修改

```
vi /etc/security/limits.conf
```

添加

```
*               hard    nofile    655350
*               soft    nofile    655350
```
重开shell会话生效。

#### 3.2.3. 设置jdk环境变量

将jdk解压至路径： /usr/users/sw/app/jdk1.8.0_144

```
vi ~/.bash_profile
```

加入

```
export JAVA_HOME=/usr/users/sw/app/jdk1.8.0_144
export PATH=$JAVA_HOME/bin:$PATH
```

重开shell会话或者 ```source ~/.bash_profile``` 生效

## 4. ElasticSearch

### 4.1. 基本信息

- ElasticSearch拟部署5个节点的集群;
- 每个ElasticSearch节点均设置为Master=true;Data=true模式;
- 索引存储使用默认配置：5分片1副本。
- 部署用户：sw
- 使用模版：现有应用虚拟机模版（微调磁盘空间、内存）
- 部署路径：/usr/users/sw/app/elasticsearch
- 数据路径：/applog/elastic/data
- 磁盘大小：/applog 挂载点在现有模版基础上扩容增加200GB，达到280GB
- 配置文件：/usr/users/sw/app/elasticsearch/config/elasticsearch.yml

```yml
cluster.name: swelastic
node.name: sw-node-1
path.data: /applog/elastic/data
path.logs: /applog/elastic/logs
network.host: 0.0.0.0
http.port: 19200
transport.tcp.port: 29200
node.master: true
node.data: true
discovery.zen.ping.unicast.hosts: ["20.17.0.51", "20.17.0.52","20.17.0.53","20.17.0.54","20.17.0.55"]
discovery.zen.minimum_master_nodes: 3
xpack.security.enabled: false

```
- JVM配置文件：/usr/users/sw/app/elasticsearch/config/jvm.options
```
-Xms6g
-Xmx6g
```


### 4.2. 安装x-pack

将下载的x-pack包上传到服务器

```
cd /usr/users/sw/app/elasticsearch
bin/elasticsearch-plugin install file:///usr/users/sw/download/x-pack-5.6.0.zip 
```
遇到提示，输入 ```y``` 回车后继续。

### 4.3. 启动ElasticSearch

以后台方式启动5个节点的ElasticSearch
```
cd /usr/users/sw/app/elasticsearch
bin/elasticsearch -d
```
观察日志
```
tail -f /applog/elastic/
```
查看集群启动情况。

```
Cluster health status changed from [YELLOW] to [GREEN]
```

集群状态变绿，则启动正常完成。

### 4.4. 注册更新license



```
curl 20.17.0.54:19200/_license
{
  "license" : {
    "status" : "active",
    "uid" : "d8caa65d-cc8e-413b-ac8a-5dec39d2823e",
    "type" : "trial",
    "issue_date" : "2017-09-16T13:18:28.857Z",
    "issue_date_in_millis" : 1505567908857,
    "expiry_date" : "2017-10-16T13:18:28.857Z",
    "expiry_date_in_millis" : 1508159908857,
    "max_nodes" : 1000,
    "issued_to" : "swelastic",
    "issuer" : "elasticsearch",
    "start_date_in_millis" : -1
  }
}
```
只有一个月有效期，去官网注册，拿到license，并上传到任意服务器更新到集群中：

```
url -XPUT 'http://20.17.0.52:19200/_licenses?acknowledge=true' -d  @licenses.json
{"acknowledged":true,"license_status":"valid"}
```


再次查看

```
curl  '20.17.0.52:19200/_license'
{
  "license" : {
    "status" : "active",
    "uid" : "76fad325-a136-4c66-9f83-23438444f959",
    "type" : "basic",
    "issue_date" : "2017-09-16T00:00:00.000Z",
    "issue_date_in_millis" : 1505520000000,
    "expiry_date" : "2018-09-16T23:59:59.999Z",
    "expiry_date_in_millis" : 1537142399999,
    "max_nodes" : 100,
    "issued_to" : "Yao Yan (TEST)",
    "issuer" : "Web Form",
    "start_date_in_millis" : 1505520000000
  }
}
```

此时，ElasticSearch集群配置完成。

### 4.5. 负载设置

因kibana设置后端ElasticSearch地址只能设置一个，所以我们用nginx对5个节点的ElasticSearch进行反向代理.

Nginx服务器地址： 20.17.0.180

- upstream

```
       upstream list_elastic {
            server 20.17.0.51:19200;
            server 20.17.0.52:19200;
            server 20.17.0.53:19200;
            server 20.17.0.54:19200;
            server 20.17.0.55:19200;
            check interval=3000 rise=2 fall=5 timeout=1000 type=http;
        }
```

- server
```
       server {
             listen 19200;
             server_name 0.0.0.0;
             location / {
                   proxy_pass http://list_elastic;
        }
```




## 5. Kibana

### 5.1. 基本信息

- Kibana拟部署2个节点;
- 前端使用nginx做反向代理;
- 部署用户：sw
- 使用模版：现有tomcat应用虚拟机模版
- 部署路径：/usr/users/sw/app/kibana
- 配置文件：/usr/users/sw/app/kibana/config/kibana.yml
- ElasticSearch地址： http://20.17.0.180:19200

```
server.port: 5601
server.host: "20.17.0.61"
server.name: "Test-Kibana-1"
elasticsearch.url: "http://20.17.0.180:19200"
kibana.index: ".kibana"
```

### 5.2. 安装x-pack

```
cd /usr/users/sw/app/kibana
bin/kibana-plugin  install file:///usr/users/sw/download/x-pack-5.6.0.zip 
```


### 5.3. 启动kibana

```
cd /usr/users/sw/app/kibana
make /applog/kibana/
nohup bin/kibana > /applog/kibana/kibana.log &
```

### 5.4. 负载设置

kibana有两个节点，前端用也使用nginx进行反向代理：

- upstream
```
        upstream list_kibana {
            server 20.17.0.61:5601;
            server 20.17.0.62:5601;
            check interval=3000 rise=2 fall=5 timeout=1000 type=http;
        }
```

- server
```
        server {
                listen   8080;
                server_name  0.0.0.0;
                rewrite ^/([^/^\.]+)$ /$1/ last;
                error_page  403              /403.html;
                error_page  404              /404.html;
                error_page  500 503 504      /500.html;
                error_page  502              /502.html;
                location /(403.html|404.html|500.html|502.html)  {
                        root html;

               }
               location / {
                  proxy_pass http://list_kibana;
                }
               location /status {
                        check_status;
                        access_log off;
                }
        }
```

## 6. Filebeat

Filebeat 作为日志采集器，需要部署在所有需要采集日志的服务器上。

### 6.1. 基本信息

- 部署用户：sw
- 部署路径：/usr/users/sw/app/filebeat
- ElasticSearch连接串：
 
```
hosts: ["20.17.0.51:19200","20.17.0.52:19200","20.17.0.53:19200","20.17.0.54:19200","20.17.0.55:19200"]
```

### 6.2. 配置文件
准备两个配置文件：

nginx配置范例：

```filebeat.prospectors:- input_type: log  paths:    - /applog/nginx/access.log    - /applog/nginx/error.log  input_type: log  document_type: first-nginx  exclude_lines: ["GET /index.html"]output.elasticsearch:  hosts:  ["20.17.0.51:19200","20.17.0.52:19200","20.17.0.53:19200","20.17.0.54:19200","20.17.0.55:19200"]
```

  Java程序log4j日志配置范例：```filebeat.prospectors:- input_type: log  paths:    - /applog/*/*.log    - /applog/*/*.out  document_type: app-log  multiline.pattern: '^\[[0-9][0-9][0-9][0-9]-[0-1][0-9]-[0-3][0-9] [0-2][0-9]:[0-5][0-9]:[0-5][0-9]'  multiline.negate: true  multiline.match: afteroutput.elasticsearch:  hosts:  ["20.17.0.51:19200","20.17.0.52:19200","20.17.0.53:19200","20.17.0.54:19200","20.17.0.55:19200"]
```
   - paths - 指定要收集的日志，可以精确指定，也可以通配符匹配； - document_type - 收集到ElasticSearch集群中的type属性值，可用来对日志分类； - exclude_lines - 排除的行，满足后后面表达式匹配的行，不进行采集； - multiline.pattern 多行日志的开始行匹配的正则表达式，用来确定日志的第一行，如果后面的行不是这个格式开头，将认为是上一行的延续，与上一行合并一起提交。




### 6.3. 手动载入索引模板



```
cd /usr/users/sw/app/filebeat
curl -H 'Content-Type: application/json' -XPUT 'http://20.17.0.180:19200/_template/filebeat' -d@filebeat.template.json
```



### 6.4. 启动filebeat

以nginx日志配置为例：

前台启动

```
./filebeat -e  -c   filebeat-ng.yml 
```

稳定无问题后换后台启动

```
nohup ./filebeat -c   filebeat-ng.yml &
```

### 6.5. 在kibana中添加索引原型（index patterns）

点击 Discover或 Management，因新建的集群，没有索引原型，都会提示```Configure an index pattern```。

![](/images/posts/2017/Snip20171001_3.png)

添加后，即可在Discover中查看到filebeat收集的日志了。


