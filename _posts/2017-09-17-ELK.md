---
layout: post
title:  "ELK日志实时分析系统搭建"
date:   2017-09-17 23:00:05
categories: ELK
tags:  ElasticSearch Filebeat kibana
excerpt: ELK日志实时分析系统搭建。
---

## 1. 概述

采用ElasticSearch作为日志存储和搜索的引擎，Filebeat代替Logstash作为日志采集器，Kibana作为前台搜索和展示界面。

## 2. 总体规划

用途 | 服务器名 | IP地址 | 类型 | 配置 | 操作系统
---|---|---|--- | ---|---
ElasticSearch节点1 | Test-ElasticSearch-1  | 20.17.0.51 | Master=true;Data=true | 4c 8GB | CentOS7
ElasticSearch节点2 | Test-ElasticSearch-2  | 20.17.0.52 | Master=true;Data=true | 4c 8GB  | CentOS7
ElasticSearch节点3 | Test-ElasticSearch-3  | 20.17.0.53 | Master=true;Data=true | 4c 8GB  | CentOS7
ElasticSearch节点4 | Test-ElasticSearch-4  | 20.17.0.54 | Master=true;Data=true | 4c 8GB  | CentOS7
ElasticSearch节点5 | Test-ElasticSearch-5  | 20.17.0.55 | Master=true;Data=true | 4c 8GB | CentOS7
Kibana节点1 | Test-Kibana-1 | 20.17.0.61 | |  4c 4GB  | CentOS7
Kibana节点2 | Test-Kibana-2 | 20.17.0.62 | |  4c 4GB  | CentOS7
ningx（已有） | nginx-1 | 20.17.0.180 | |  2c 4GB | CentOS7

## 3. 准备工作

### 3.1. 软件准备

分别使用软件当前的最新稳定版本：

- ElasticSearch 5.6.0

```
https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.0.tar.gz
```

-  Kibana 5.6.0

```
https://artifacts.elastic.co/downloads/kibana/kibana-5.6.0-linux-x86_64.tar.gz
```

- Filebeat 5.6.0

```
https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.0-linux-x86_64.tar.gz
```

- X-Pack 5.6.0

```
https://artifacts.elastic.co/downloads/packs/x-pack/x-pack-5.6.0.zip
```

- Java SE Development Kit 8u144

```
http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
```

- 注册一个Free Basic License，使用X-Pack功能需要每年免费续License

```
https://register.elastic.co/
```

所有的下载文件，上传至 ```/app/download/``` 路径下。

### 3.2. 系统参数设置

#### 3.2.1. vm.max_map_count

```
vi /etc/sysctl.conf 
```

添加

```
vm.max_map_count=655360
```

然后执行

```
sysctl -p
```

立即生效。

#### 3.2.2. OpenFiles数修改

```
vi /etc/security/limits.conf
```

添加

```
*               hard    nofile    655350
*               soft    nofile    655350
```

重开shell会话生效。

#### 3.2.3. 设置jdk环境变量

将jdk解压至路径： /app/jdk1.8.0_144

```
vi ~/.bash_profile
```

加入

```
export JAVA_HOME=/app/jdk1.8.0_144
export PATH=$JAVA_HOME/bin:$PATH
```

重开shell会话或者 ```source ~/.bash_profile``` 生效

## 4. ElasticSearch

### 4.1. 基本信息

- ElasticSearch拟部署5个节点的集群;
- 每个ElasticSearch节点均设置为Master=true;Data=true模式;
- 索引存储使用默认配置：5分片1副本。

```yml
cluster.name: testelastic
node.name: test-node-1
path.data: /elastic/data
path.logs: /elastic/logs
network.host: 0.0.0.0
http.port: 9200
transport.tcp.port: 9300
node.master: true
node.data: true
discovery.zen.ping.unicast.hosts: ["20.17.0.51", "20.17.0.52","20.17.0.53","20.17.0.54","20.17.0.55"]
discovery.zen.minimum_master_nodes: 3
xpack.security.enabled: false

```
- JVM配置文件：jvm.options
```
-Xms6g
-Xmx6g
```


### 4.2. 安装x-pack

将下载的x-pack包上传到服务器

```
cd /app/elasticsearch
bin/elasticsearch-plugin install file:///path/to/x-pack-5.6.0.zip 
```
遇到提示，输入 ```y``` 回车后继续。

### 4.3. 启动ElasticSearch

以后台方式启动5个节点的ElasticSearch

```
cd /app/elasticsearch
bin/elasticsearch -d
```

观察日志,查看集群启动情况。

```
Cluster health status changed from [YELLOW] to [GREEN]
```

集群状态变绿，则启动正常完成。

### 4.4. 注册更新license



```
curl 20.17.0.54:9200/_license
{
  "license" : {
    "status" : "active",
    "uid" : "d8caa65d-cc8e-413b-ac8a-5dec39d2823e",
    "type" : "trial",
    "issue_date" : "2017-09-16T13:18:28.857Z",
    "issue_date_in_millis" : 1505567908857,
    "expiry_date" : "2017-10-16T13:18:28.857Z",
     ........
  }
}
```
只有一个月有效期，去官网注册，拿到license，并上传到任意服务器更新到集群中：

```
url -XPUT 'http://20.17.0.52:9200/_licenses?acknowledge=true' -d  @licenses.json
{"acknowledged":true,"license_status":"valid"}
```


再次查看

```
curl  '20.17.0.52:9200/_license'
{
  "license" : {
    "status" : "active",
    "uid" : "xxxxxxx",
    "type" : "basic",
    "issue_date" : "2017-09-16T00:00:00.000Z",
    "issue_date_in_millis" : 1505520000000,
    "expiry_date" : "2018-09-16T23:59:59.999Z",
     .......
  }
}
```

此时，ElasticSearch集群配置完成。

### 4.5. 负载设置

因kibana设置后端ElasticSearch地址只能设置一个，所以我们用nginx对5个节点的ElasticSearch进行反向代理.

Nginx服务器地址： 20.17.0.180

- upstream

```
       upstream elastic {
            server 20.17.0.51:9200;
            server 20.17.0.52:9200;
            server 20.17.0.53:9200;
            server 20.17.0.54:9200;
            server 20.17.0.55:9200;
            check interval=3000 rise=2 fall=5 timeout=1000 type=http;
        }
```

- server
```
       server {
             listen 9200;
             server_name 0.0.0.0;
             location / {
                   proxy_pass http://elastic;
        }
```




## 5. Kibana

### 5.1. 基本信息

- Kibana拟部署2个节点;
- 前端使用nginx做反向代理;
- ElasticSearch地址： http://20.17.0.180:9200

```
server.port: 5601
server.host: "20.17.0.61"
server.name: "Test-Kibana-1"
elasticsearch.url: "http://20.17.0.180:9200"
kibana.index: ".kibana"
```

### 5.2. 安装x-pack

```
cd /usr/users/sw/app/kibana
bin/kibana-plugin  install file:///path/to/x-pack-5.6.0.zip 
```


### 5.3. 启动kibana

```
nohup bin/kibana > /kibana/kibana.log &
```

### 5.4. 负载设置

kibana有两个节点，前端用也使用nginx进行反向代理：

- upstream
```
        upstream kibana {
            server 20.17.0.61:5601;
            server 20.17.0.62:5601;
            check interval=3000 rise=2 fall=5 timeout=1000 type=http;
        }
```

- server
```
        server {
                listen   8080;
                server_name  0.0.0.0;
               }
               location / {
                  proxy_pass http://kibana;
                }
        }
```

## 6. Filebeat

Filebeat 作为日志采集器，需要部署在所有需要采集日志的服务器上。

### 6.1. 基本信息

- ElasticSearch连接串：
 
```
hosts: ["20.17.0.51:9200","20.17.0.52:9200","20.17.0.53:9200","20.17.0.54:9200","20.17.0.55:9200"]
```

### 6.2. 配置文件
准备两个配置文件：

nginx配置范例：

```filebeat.prospectors:- input_type: log  paths:    - /path/to/access.log    - /path/to/error.log  input_type: log  document_type: nginxoutput.elasticsearch:  hosts:  ["20.17.0.51:9200","20.17.0.52:9200","20.17.0.53:9200","20.17.0.54:9200","20.17.0.55:9200"]
```

  Java程序log4j日志配置范例：```filebeat.prospectors:- input_type: log  paths:    - /path/to/*.log    - /path/*/*.out  document_type: app-log  multiline.pattern: '^\[[0-9][0-9][0-9][0-9]-[0-1][0-9]-[0-3][0-9] [0-2][0-9]:[0-5][0-9]:[0-5][0-9]'  multiline.negate: true  multiline.match: afteroutput.elasticsearch:  hosts:  ["20.17.0.51:9200","20.17.0.52:9200","20.17.0.53:9200","20.17.0.54:9200","20.17.0.55:9200"]
```
   - paths - 指定要收集的日志，可以精确指定，也可以通配符匹配； - document_type - 收集到ElasticSearch集群中的type属性值，可用来对日志分类； - multiline.pattern 多行日志的开始行匹配的正则表达式，用来确定日志的第一行，如果后面的行不是这个格式开头，将认为是上一行的延续，与上一行合并一起提交。




### 6.3. 手动载入索引模板



```
cd /app/filebeat
curl -H 'Content-Type: application/json' -XPUT 'http://20.17.0.180:9200/_template/filebeat' -d@filebeat.template.json
```



### 6.4. 启动filebeat

以nginx日志配置为例：

前台启动

```
./filebeat -e  -c   filebeat-ng.yml 
```

稳定无问题后换后台启动

```
nohup ./filebeat -c   filebeat-ng.yml &
```

### 6.5. 在kibana中添加索引原型（index patterns）

点击 Discover或 Management，因新建的集群，没有索引原型，都会提示```Configure an index pattern```。

![](/images/posts/2017/Snip20171001_3.png)

添加后，即可在Discover中查看到filebeat收集的日志了。


